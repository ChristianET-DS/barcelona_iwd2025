{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b960028c-8498-4277-b629-20046e0064e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install --upgrade --quiet google-cloud-aiplatform google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ab68893-d941-4b7c-b659-97f0b8c0e413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install --upgrade --user --quiet google-cloud-aiplatform google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7c17c3-f2c5-43d4-8897-a2881a4a6b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Markdown, display\n",
    "from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore\n",
    "from vertexai import rag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d795ac-5b9f-4c31-a477-891b9bb05a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import IPython\n",
    "\n",
    "#app = IPython.Application.instance()\n",
    "#app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa583bb-10a3-4e32-a513-68637b1944f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "from google import genai\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"[iwd2025]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[iwd2025]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Start api with Vertex \n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f669c37c-7298-4956-8c91-8121b8dc4526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Currently supports Google first-party embedding models\n",
    "EMBEDDING_MODEL = \"publishers/google/models/text-embedding-004\"  # @param {type:\"string\", isTemplate: true}\n",
    "\n",
    "#rag de vertex create a corpus using the embeding 004\n",
    "rag_corpus = rag.create_corpus(\n",
    "    display_name=\"my-rag-corpus\",\n",
    "    backend_config=rag.RagVectorDbConfig(\n",
    "        rag_embedding_model_config=rag.RagEmbeddingModelConfig(\n",
    "            vertex_prediction_endpoint=rag.VertexPredictionEndpoint(\n",
    "                publisher_model=EMBEDDING_MODEL\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "#https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/rag-api\n",
    "#The Vertex AI RAG Engine is a component of the Vertex AI platform, which facilitates Retrieval-Augmented Generation (RAG). RAG Engine enables Large Language Models (LLMs) to access and incorporate data from external knowledge sources, such as documents and databases. By using RAG, LLMs can generate more accurate and informative LLM responses.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d156b7-5b03-4755-a230-153ac7c185f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListRagCorporaPager<rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/2305843009213693952\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1741357986\n",
       "    nanos: 581625000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741357986\n",
       "    nanos: 581625000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/3379951520341557248\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1741628569\n",
       "    nanos: 683768000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741628569\n",
       "    nanos: 683768000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/6838716034162098176\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1741629123\n",
       "    nanos: 986240000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741629123\n",
       "    nanos: 986240000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/137359788634800128\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1741635483\n",
       "    nanos: 107202000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741635483\n",
       "    nanos: 107202000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/6917529027641081856\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1742415351\n",
       "    nanos: 358554000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1742415351\n",
       "    nanos: 358554000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/3458764513820540928\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1742415570\n",
       "    nanos: 940860000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1742415570\n",
       "    nanos: 940860000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/5188146770730811392\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1742415602\n",
       "    nanos: 213231000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1742415602\n",
       "    nanos: 213231000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/1729382256910270464\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1742636019\n",
       "    nanos: 454954000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1742636019\n",
       "    nanos: 454954000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/8646911284551352320\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1742636197\n",
       "    nanos: 16279000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1742636197\n",
       "    nanos: 16279000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "rag_corpora {\n",
       "  name: \"projects/iwd2025/locations/us-central1/ragCorpora/2594073385365405696\"\n",
       "  display_name: \"my-rag-corpus\"\n",
       "  create_time {\n",
       "    seconds: 1742636290\n",
       "    nanos: 267258000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1742636290\n",
       "    nanos: 267258000\n",
       "  }\n",
       "  corpus_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "  vector_db_config {\n",
       "    rag_managed_db {\n",
       "    }\n",
       "    rag_embedding_model_config {\n",
       "      vertex_prediction_endpoint {\n",
       "        endpoint: \"projects/iwd2025/locations/us-central1/publishers/google/models/text-embedding-004\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rag.list_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a11d398-afa5-46b8-9968-b5147ab80aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.md\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by allowing them to access and incorporate external data sources when generating responses. Here's a breakdown:\n",
    "\n",
    "**What it is:**\n",
    "\n",
    "* **Combining Retrieval and Generation:**\n",
    "    * RAG combines the strengths of information retrieval systems (like search engines) with the generative power of LLMs.\n",
    "    * It enables LLMs to go beyond their pre-trained data and access up-to-date and specific information.\n",
    "* **How it works:**\n",
    "    * When a user asks a question, the RAG system first retrieves relevant information from external data sources (e.g., databases, documents, web pages).\n",
    "    * This retrieved information is then provided to the LLM as additional context.\n",
    "    * The LLM uses this augmented context to generate a more accurate and informative response.\n",
    "\n",
    "**Why it's helpful:**\n",
    "\n",
    "* **Access to Up-to-Date Information:**\n",
    "    * LLMs are trained on static datasets, so their knowledge can become outdated. RAG allows them to access real-time or frequently updated information.\n",
    "* **Improved Accuracy and Factual Grounding:**\n",
    "    * RAG reduces the risk of LLM \"hallucinations\" (generating false or misleading information) by grounding responses in verified external data.\n",
    "* **Enhanced Contextual Relevance:**\n",
    "    * By providing relevant context, RAG enables LLMs to generate more precise and tailored responses to specific queries.\n",
    "* **Increased Trust and Transparency:**\n",
    "    * RAG can provide source citations, allowing users to verify the information and increasing trust in the LLM's responses.\n",
    "* **Cost Efficiency:**\n",
    "    * Rather than constantly retraining large language models, RAG allows for the introduction of new data in a more cost effective way.\n",
    "\n",
    "In essence, RAG bridges the gap between the vast knowledge of LLMs and the need for accurate, current, and contextually relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1897fa8-1912-4a40-b42d-5b8dc55736f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#super easy to upload file \n",
    "rag_file = rag.upload_file(\n",
    "    corpus_name=rag_corpus.name,\n",
    "    path=\"test.md\",\n",
    "    display_name=\"test.md\",\n",
    "    description=\"my test file\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8190fc92-3eb2-48ba-b0d7-c50b0ece7ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bucket data \n",
    "INPUT_GCS_BUCKET = (\n",
    "    \"gs://grammarbucketrag/\"\n",
    ")\n",
    "\n",
    "response = rag.import_files(\n",
    "    corpus_name=rag_corpus.name,\n",
    "    paths=[INPUT_GCS_BUCKET],  #my bucket\n",
    "    # Optional\n",
    "    transformation_config=rag.TransformationConfig(\n",
    "        chunking_config=rag.ChunkingConfig(chunk_size=1024, chunk_overlap=100)  # CHUNK BUCKETS\n",
    "    ),\n",
    "    max_embedding_requests_per_min=900,  # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a6cc9c-ad9c-4968-9298-ff66cd1b0e42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imported_rag_files_count: 3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4691d2dd-9722-4483-a804-fb4d01c4e4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListRagFilesPager<rag_files {\n",
       "  name: \"projects/540591311657/locations/us-central1/ragCorpora/6838716034162098176/ragFiles/5386472047294458114\"\n",
       "  display_name: \"test.md\"\n",
       "  description: \"my test file\"\n",
       "  create_time {\n",
       "    seconds: 1741629133\n",
       "    nanos: 784242000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741629133\n",
       "    nanos: 784242000\n",
       "  }\n",
       "  direct_upload_source {\n",
       "  }\n",
       "  file_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "}\n",
       "rag_files {\n",
       "  name: \"projects/540591311657/locations/us-central1/ragCorpora/6838716034162098176/ragFiles/5386472098916773497\"\n",
       "  display_name: \"7b2d049c2da59f7764990a3588d518c3.pdf\"\n",
       "  create_time {\n",
       "    seconds: 1741629139\n",
       "    nanos: 937508000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741629139\n",
       "    nanos: 937508000\n",
       "  }\n",
       "  gcs_source {\n",
       "    uris: \"gs://grammarbucketrag/7b2d049c2da59f7764990a3588d518c3.pdf\"\n",
       "  }\n",
       "  file_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "}\n",
       "rag_files {\n",
       "  name: \"projects/540591311657/locations/us-central1/ragCorpora/6838716034162098176/ragFiles/5386472101001005969\"\n",
       "  display_name: \"Sicher_B2_Grammatikuebersicht.pdf\"\n",
       "  create_time {\n",
       "    seconds: 1741629140\n",
       "    nanos: 194377000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741629140\n",
       "    nanos: 194377000\n",
       "  }\n",
       "  gcs_source {\n",
       "    uris: \"gs://grammarbucketrag/Sicher_B2_Grammatikuebersicht.pdf\"\n",
       "  }\n",
       "  file_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "}\n",
       "rag_files {\n",
       "  name: \"projects/540591311657/locations/us-central1/ragCorpora/6838716034162098176/ragFiles/5386472106074991773\"\n",
       "  display_name: \"7480-63_001_01_deutsch_kompakt.pdf\"\n",
       "  create_time {\n",
       "    seconds: 1741629140\n",
       "    nanos: 869986000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1741629140\n",
       "    nanos: 869986000\n",
       "  }\n",
       "  gcs_source {\n",
       "    uris: \"gs://grammarbucketrag/7480-63_001_01_deutsch_kompakt.pdf\"\n",
       "  }\n",
       "  file_status {\n",
       "    state: ACTIVE\n",
       "  }\n",
       "}\n",
       ">"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.list_files('projects/540591311657/locations/us-central1/ragCorpora/6838716034162098176')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f112f6-bb55-41c8-8443-80c8610c1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retival object  get from the rag the similatiry k 19\n",
    "# Create a tool for the RAG Corpus\n",
    "rag_retrieval_tool = Tool(\n",
    "    retrieval=Retrieval(\n",
    "        vertex_rag_store=VertexRagStore(\n",
    "            rag_corpora=[rag_corpus.name],\n",
    "            similarity_top_k=10,\n",
    "            vector_distance_threshold=0.5,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800ef528-d0c8-473b-ad8f-fe29bf5c3c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "MODEL_ID = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc8df90-d65e-4a64-9f3d-79926e335729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Zweiteilige Konnektoren haben verschiedene Funktionen: Aufzählungen, Alternativen, Gegensätze und Einschränkungen. Sie können an verschiedenen Positionen stehen.\n",
       "\n",
       "Beispiele:\n",
       "\n",
       "*   **Aufzählung (positiv):** Wir haben sowohl in derselben Firma gearbeitet als auch im selben Chor gesungen.\n",
       "*   **Aufzählung (negativ):** Es macht weder meinem Freund noch mir etwas aus.\n",
       "*   **Alternative:** Entweder gehen wir etwas essen oder wir treffen uns zu Hause.\n",
       "*   **Gegensatz:** Einerseits würde ich ihn gern treffen, andererseits bringt das nichts.\n",
       "*   **Einschränkung:** Wir sehen uns zwar nicht mehr oft, aber wir bleiben Freunde."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Erklärt mir die zweiteilige konnentoren\",\n",
    "    config=GenerateContentConfig(tools=[rag_retrieval_tool]),\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58e6f44-1df0-4794-bb46-c5dac19faa7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (976360472.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Modalverben können auch ohne Infinitiv gebraucht werden (= Vollverb):\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Modalverben können auch ohne Infinitiv gebraucht werden (= Vollverb):\n",
    "Muss ich Petra schreiben?\n",
    "Du musst nicht, aber du kannst, wenn du willst.\n",
    "Nikolas möchte einen Kaffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bae475-0c98-4d8e-8ce1-7198fc1f8157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49477cf-e4d8-49a2-a1c2-87eb0aecdeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
